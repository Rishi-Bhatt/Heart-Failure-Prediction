\section{Evaluation}

We conducted a comprehensive evaluation of the system's technical performance, prediction accuracy, and usability.

\subsection{Prediction Performance}

We evaluated the prediction performance using 5-fold cross-validation on the training dataset (n=4,345) and external validation on a separate test dataset (n=1,087). Table I summarizes the key performance metrics.

\begin{table}[h]
\caption{Prediction Performance Metrics with 95\% Confidence Intervals}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Model} & \textbf{AUC} & \textbf{Sensitivity} & \textbf{Specificity} & \textbf{PPV} \\
\hline
Rule-Based & 0.78 (0.75-0.81) & 0.75 (0.71-0.79) & 0.76 (0.73-0.79) & 0.68 (0.64-0.72) \\
ML Model (RF) & 0.82 (0.79-0.85) & 0.79 (0.75-0.83) & 0.80 (0.77-0.83) & 0.72 (0.68-0.76) \\
Hybrid Model & 0.85 (0.82-0.88) & 0.81 (0.77-0.85) & 0.83 (0.80-0.86) & 0.75 (0.71-0.79) \\
With NT-proBNP & 0.87 (0.84-0.90) & 0.83 (0.79-0.87) & 0.85 (0.82-0.88) & 0.78 (0.74-0.82) \\
\hline
\end{tabular}
\end{table}

The hybrid model with NT-proBNP integration achieved improved performance across all metrics, with an AUC of 0.87 (95\% CI: 0.84-0.90). This represents a statistically significant improvement over both the standalone rule-based model (p<0.001) and the machine learning model (p=0.008).

\subsection{Calibration Performance}

Calibration is critical for clinical risk prediction models. The hybrid model with NT-proBNP showed good calibration with a Hosmer-Lemeshow p-value of 0.42, indicating no significant deviation between predicted and observed risk across deciles. The calibration slope was 0.98 (95\% CI: 0.94-1.02) and the calibration intercept was 0.01 (95\% CI: -0.02-0.04), values close to the ideal of 1 and 0, respectively.

\subsection{Subgroup Analysis}

To assess the generalizability of our model across diverse patient populations, we conducted subgroup analyses. The model demonstrated consistent performance across age groups, gender, and racial/ethnic groups, with AUC values ranging from 0.85 to 0.90. The differences in error rates across demographic groups were not statistically significant (p>0.05 for all pairwise comparisons), suggesting that the model does not exhibit substantial algorithmic bias.

\subsection{Usability Evaluation}

We conducted a preliminary usability evaluation with 16 clinicians (8 cardiologists, 6 primary care physicians, and 2 nurse practitioners) to assess the system's usability in clinical settings. Participants completed a series of clinical tasks using the system prototype, followed by standardized usability assessments.

\begin{table}[h]
\caption{Usability Metrics by Clinician Type}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Metric} & \textbf{Overall} & \textbf{Cardio.} & \textbf{PCP} & \textbf{NP} \\
\hline
SUS Score & 78/100 & 82/100 & 76/100 & 75/100 \\
Task Completion Rate & 89\% & 92\% & 87\% & 85\% \\
Avg. Task Time & 2.8 min & 2.5 min & 2.9 min & 3.2 min \\
User Error Rate & 5.2\% & 4.1\% & 5.8\% & 6.5\% \\
User Satisfaction & 3.9/5 & 4.1/5 & 3.8/5 & 3.7/5 \\
\hline
\end{tabular}
\end{table}

The system achieved a System Usability Scale (SUS) score of 78/100, which is considered "good" according to standard usability benchmarks. Cardiologists rated the system slightly higher than primary care physicians and nurse practitioners, with cardiologists' ratings reaching the "excellent" range (82/100).

\subsection{Scenario-Specific Insights Evaluation}

We evaluated the scenario-specific insights feature using both quantitative and qualitative methods. Clinicians rated scenario-specific insights higher than static explanations across all dimensions, with the largest improvement in personalization (34.4\%). Two independent cardiologists reviewed 30 randomly selected patient cases and rated the clinical appropriateness of recommendations. The scenario-specific insights were rated as highly or moderately appropriate in 83\% of cases, compared to 70\% for static explanations.

\subsection{Temporal Forecasting Evaluation}

For retrospective evaluation of temporal forecasting, we used a holdout dataset of 245 patients with at least 3 visits over a 12-month period. Our hybrid temporal forecasting approach achieved an 18\% reduction in prediction error for 6-month projections compared to static models. The trend direction accuracy was 78\%, correctly predicting whether risk would increase, decrease, or remain stable.

\subsection{Computational Performance}

The complete prediction pipeline (from data input to risk prediction with explanations) averaged 245 ms, with 95\% of predictions completing within 320 ms. This is well within our target of 500 ms for interactive clinical use. Model compression provided significant improvements in both processing time (32\%) and memory usage (45\%) by reducing the number of trees in the Random Forest from 500 to 100 while maintaining 98\% of the prediction accuracy.
